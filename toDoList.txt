This file will track items that either are necessary to complete in the future
 and/or options that should be explored and possibly implemented


ToDo:
-----------------------------------------------------------
- Implement basic Kelly Criterion script
- Refactor the data handler class away from the HistoricCSVHandler subclass and
  towards a SecuritiesMasterDataHandler subclass
- Similarly a few other subclasses that will in the future help handle more
  robust algothimic/automated trading would be to implement: QuandlDataHandler,
  and InteractiveBrokersMarketFeedDataHandler subclasses
- Integrate risk/performance management more tightly with the portfolio class
  and testing framework. Currently generate_naive_order in portfolio.py uses an
  arbitrary fill quantity of 100, position sizing can easily be integrated in
  here along with an entire suite of risk/performance tools.





ToExplore:
-----------------------------------------------------------
- Check out Python's ScraPy library built on the Twisted framework for
  making the price retrieval in the Database assembly folder more
  concurrent (right now it's sequentially by symbol) and therefore a great
  deal
  faster)

- ScraPy helps scrape the web, some strategies rely on inferring sentiment
from
  online web/text resources. Check out these two books for further insight:
     [14] M. A. Russell. 21 Recipes for Mining Twitter. O’Reilly Media, 2011
     [15] M. A. Russell. Mining the Social Web, 2nd Ed. O’Reilly Media, 2013

- Look into a NoSQL db framework like MongoDB for storing unstructured/ text
  information

- Look into storage of tick data (much higher volume of data) per exchange.
  HDF5, kdb, or flat files?

- Similarly the historical representation / even market simulator of a limit
  order book can be advantageous (and even necessary) for higher frequency
  strategies. Look into creating. This may be a fairly large task

- Since we will be using historical yahoo market data (equities), we will be
  exposed to the phenomena of "back-filling". This is when historical data is
  corrected (or changed for whatever reason) at a future date. This poses
  potential problems as backtesting results that should be reproducable/ remain
  relatively consistent may be affected. A solution could be to keep a separate
  logging table which tracks whenever a historical data point is modified and
  stores the log.

- Look into the Quandl python package. Although the
  YahooFinance_Pandas_Quandl_DTNIQFeed/Quandl/quanfl_Python_ContractsDownload.py
  file works decently well, it is most likely more "correct" and scalable to
  use the Quandl package. For example whenever the version is updated through
  the  web the API links may break, ie from going to v1 -> v2 -> v3 I've had to
  update the script. Hopefully the Quandl package is more robust and takes care
  of this. The package will probably also contain additional useful
  functionality to explore and potentially leverage.
- perpetualSeries_ContinousFuturesContractModel.py needs to accept a list of
  inputs. Also it should there should be a short helper function to help derive
  the current near contract and far contract as opposed to changing the
  hardcoded values each expiration date
  - make plot_2Price_Series take dates as inputs in cADF.py
  - make the plot functions in cADF.py all subplots on the same window for
    brevity
- add indicator and filter subclasses for a class hierarchy in the strategy.py
  file
- in portfolio.py implement margin calculation and tracking as well as shorting
  requirements logic
- Include more error handling logic in ib_execution.py
- update create_initial_order_id in ib_execution to query IB for the latest
  next available ID and use that for tracking submitted orders
